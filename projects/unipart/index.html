---
layout: project
title : UniPart - Part-Level 3D Generation
navbar_title: UniPart
container_class: container-xl
---

<!-- Hero Section -->
<section class="hero-section">
  <div class="container">
    <div class="row justify-content-center text-center">
      <div class="col-lg-10">
        <h1 class="project-title mb-3">UniPart: Part-Level 3D Generation with Unified 3D Geom-Seg Latents</h1>

        <h5 class="project-authors mb-3">
          <a href="https://xfanhe.github.io/" target="_blank">Xufan He</a><sup class="sup-normal">1,2*</sup>,
          <a href="https://yushuang-wu.github.io/" target="_blank">Yushuang Wu</a><sup class="sup-normal">2*</sup>,
          <span>Xiaoyang Guo</span><sup class="sup-normal">2</sup>,
          <a href="https://hugoycj.github.io/" target="_blank">Chongjie Ye</a><sup class="sup-normal">2,3</sup>,
          <span>Jiaqing Zhou</span><sup class="sup-normal">2</sup>,
          <span>Tianlei Hu</span><sup class="sup-normal">2</sup>,
          <a href="https://gaplab.cuhk.edu.cn/pages/people" target="_blank">Xiaoguang Han</a><sup class="sup-normal">3</sup>,
          <a href="https://dongdu3.github.io/" target="_blank">Dong Du</a><sup class="sup-normal">1,†</sup>
        </h5>

        <p class="text-muted small mb-4">
          <sup class="sup-sm">1</sup><span class="institution">Nanjing University of Science and Technology</span>
          <sup class="sup-sm">2</sup><span class="institution">ByteDance</span>
          <sup class="sup-sm">3</sup><span class="institution">The Chinese University of Hong Kong, Shenzhen</span>
          <br>
          <sup>*</sup>Equal Contribution &nbsp;&nbsp;
          <sup>†</sup>Corresponding Author
        </p>

        <!-- Links -->
        <div class="mb-4">
          <a href="https://arxiv.org/abs/2512.09435" target="_blank" class="btn btn-outline-primary mr-2 mb-2">
            <i class="fas fa-file-pdf"></i> Paper
          </a>
          <a href="#" target="_blank" class="btn btn-outline-dark mr-2 mb-2">
            <i class="fab fa-github"></i> Code
          </a>
          <a href="#" target="_blank" class="btn btn-outline-info mr-2 mb-2">
            <i class="fas fa-database"></i> Model
          </a>
        </div>

        <hr class="my-4">
        <p class="lead">
          Part-level 3D generation with <strong>unified 3D geometry and segmentation latents</strong>.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Video Demo -->
<section class="section">
  <div class="container">
    <div class="row justify-content-center text-center">
      <div class="col-lg-10">
        <h2 class="mb-4">Video Demo</h2>
        <div class="card border-0 shadow-sm">
          <video
              src="{{ '/projects/unipart/assets/videos/demo.mp4' | relative_url }}"
              class="card-img-top"
              controls
              autoplay
              muted
              loop
              playsinline>
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container">
    <div class="row justify-content-center text-center">
      <div class="col-lg-10">
        <h2>Abstract</h2>
        <p class="text-justify">
          Part-level 3D generation is essential for applications requiring decomposable and structured 3D synthesis. However, existing methods either rely on implicit part segmentation with limited granularity control or depend on strong external segmenters trained on large annotated datasets. In this work, we observe that part awareness emerges naturally during whole-object geometry learning and propose Geom-Seg VecSet, a unified geometry-segmentation latent representation that jointly encodes object geometry and part-level structure. Building on this representation, we introduce UniPart, a two-stage latent diffusion framework for image-guided part-level 3D generation. The first stage performs joint geometry generation and latent part segmentation, while the second stage conditions part-level diffusion on both whole-object and part-specific latents. A dual-space generation scheme further enhances geometric fidelity by predicting part latents in both global and canonical spaces. Extensive experiments demonstrate that UniPart achieves superior segmentation controllability and part-level geometric quality compared with existing approaches.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Method Overview -->
<section class="section bg-light">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-lg-10">
        <h2 class="text-center mb-4">Method Overview</h2>
        <img src="{{ '/projects/unipart/assets/images/pipeline.jpg' | relative_url }}" alt="Method Pipeline" class="img-fluid rounded shadow-sm w-100">
        <p class="mt-3 text-muted">
          Given input point cloud, per-point feature and part bounding boxes are extracted. Global and part
          conditions are obtained by stacking geometry token with interpolated semantic features. They are injected to
          multi-part diffusion process to guide shape decomposition.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX -->
<section class="section">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-lg-10">
        <h2 class="text-center mb-4">BibTeX</h2>
        <div class="card border-0 shadow-sm">
          <div class="card-body p-3">
            <pre class="mb-0"><code>@misc{he2025unipartpartlevel3dgeneration,
      title={UniPart: Part-Level 3D Generation with Unified 3D Geom-Seg Latents}, 
      author={Xufan He and Yushuang Wu and Xiaoyang Guo and Chongjie Ye and Jiaqing Zhou and Tianlei Hu and Xiaoguang Han and Dong Du},
      year={2025},
      eprint={2512.09435},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.09435}, 
}</code></pre>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
